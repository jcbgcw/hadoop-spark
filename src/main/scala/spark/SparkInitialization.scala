val sc = new org.apache.spark.SparkContext(new org.apache.spark.SparkConf().setAppName("Spark shell"))
val sqlContext: org.apache.spark.sql.SQLContext = new org.apache.spark.sql.hive.HiveContext(sc)

import scala.Predef._
import org.apache.spark.SparkContext._
import sqlContext.implicits._
import sqlContext.sql
import org.apache.spark.sql.functions._

///////////WRITE CODE BELOW /////////////////////////

println("\n========= 050-Spark Conf ===========")
println(sc.getConf.toDebugString)
"""
  |park.app.id=application_1523883615638_0001
  |spark.app.name=Spark shell
  |spark.authenticate=false
  |spark.authenticate.enableSaslEncryption=false
  |spark.driver.appUIAddress=http://10.0.2.15:4040
  |spark.driver.extraLibraryPath=/usr/lib/hadoop/lib/native
  |spark.driver.host=10.0.2.15
  |spark.driver.port=46153
  |spark.dynamicAllocation.enabled=true
  |spark.dynamicAllocation.executorIdleTimeout=60
  |spark.dynamicAllocation.minExecutors=0
  |spark.dynamicAllocation.schedulerBacklogTimeout=1
  |spark.eventLog.dir=hdfs://quickstart.cloudera:8020/user/spark/applicationHistory
  |spark.eventLog.enabled=true
  |spark.executor.extraLibraryPath=/usr/lib/hadoop/lib/native
  |spark.executor.id=driver
  |spark.externalBlockStore.folderName=spark-a4cbdcbe-ca69-4d79-b32e-9bee7193c056
  |spark.extraListeners=com.cloudera.spark.lineage.ClouderaNavigatorListener
  |spark.jars=
  |spark.lineage.enabled=false
  |spark.lineage.log.dir=/var/log/spark/lineage
  |spark.master=yarn-client
  |spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_HOSTS=quickstart.cloudera
  |spark.org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter.param.PROXY_URI_BASES=http://quickstart.cloudera:8088/proxy/application_1523883615638_0001
  |spark.repl.class.outputDir=/tmp/spark-55b26afc-0ac1-4d25-8ed5-19331c908ab8/repl-f870fc62-0d55-402b-b509-23694803c304
  |spark.repl.class.uri=spark://10.0.2.15:46153/classes
  |spark.serializer=org.apache.spark.serializer.KryoSerializer
  |spark.shuffle.encryption.enabled=false
  |spark.shuffle.service.enabled=true
  |spark.shuffle.service.port=7337
  |spark.sql.queryExecutionListeners=com.cloudera.spark.lineage.ClouderaNavigatorListener
  |spark.submit.deployMode=client
  |spark.ui.enabled=true
  |spark.ui.filters=org.apache.hadoop.yarn.server.webproxy.amfilter.AmIpFilter
  |spark.ui.killEnabled=true
  |spark.yarn.am.extraLibraryPath=/usr/lib/hadoop/lib/native
  |spark.yarn.historyServer.address=http://quickstart.cloudera:18088
  |spark.yarn.historyServer.allowTracking=true
  |spark.yarn.jar=local:/usr/lib/spark/lib/spark-assembly.jar
  |
"""

println("\n========= SQL Context ===========")

val debugString = sqlContext.getAllConfs.toArray.sorted.map { case (k, v) => k + "=" + v }.mkString("\n")
println(debugString)
"""
  |_hive.hdfs.session.path=file:/tmp/spark-7a09d126-987b-45d1-b5a6-d2c3d5a8dca5/scratch/cloudera/9368ca67-5d25-4b95-ab3c-c89d8160f364
  |_hive.local.session.path=/tmp/cloudera/9368ca67-5d25-4b95-ab3c-c89d8160f364
  |_hive.tmp_table_space=file:/tmp/spark-7a09d126-987b-45d1-b5a6-d2c3d5a8dca5/scratch/cloudera/9368ca67-5d25-4b95-ab3c-c89d8160f364/_tmp_space.db
  |adl.feature.ownerandgroup.enableupn=false
  |datanucleus.autoCreateSchema=true
  |datanucleus.autoStartMechanismMode=checked
  |datanucleus.cache.level2=false
  |datanucleus.cache.level2.type=none
  |datanucleus.connectionPoolingType=BONECP
  |datanucleus.fixedDatastore=false
  |datanucleus.identifierFactory=datanucleus1
  |datanucleus.plugin.pluginRegistryBundleCheck=LOG
  |datanucleus.rdbms.datastoreAdapterClassName=org.datanucleus.store.rdbms.adapter.DerbyAdapter
  |datanucleus.rdbms.useLegacyNativeValueStrategy=true
  |datanucleus.storeManagerType=rdbms
  |datanucleus.transactionIsolation=read-committed
  |datanucleus.validateColumns=false
  |datanucleus.validateConstraints=false
  |datanucleus.validateTables=false
  |dfs.balancer.address=0.0.0.0:0
  |dfs.balancer.block-move.timeout=0
  |dfs.balancer.keytab.enabled=false
  |dfs.balancer.max-no-move-interval=60000
  |dfs.block.access.key.update.interval=600
  |dfs.block.access.token.enable=false
  |dfs.block.access.token.lifetime=600
  |dfs.block.scanner.volume.bytes.per.second=1048576
  |dfs.blockreport.initialDelay=0
  |dfs.blockreport.intervalMsec=21600000
  |dfs.blockreport.split.threshold=1000000
  |dfs.blocksize=134217728
  |dfs.bytes-per-checksum=512
  |dfs.cachereport.intervalMsec=10000
  |dfs.client-write-packet-size=65536
  |dfs.client.block.write.replace-datanode-on-failure.best-effort=false
  |dfs.client.block.write.replace-datanode-on-failure.enable=true
  |dfs.client.block.write.replace-datanode-on-failure.policy=DEFAULT
  |dfs.client.block.write.retries=3
  |dfs.client.cached.conn.retry=3
  |dfs.client.context=default
  |dfs.client.datanode-restart.timeout=30
  |dfs.client.domain.socket.data.traffic=false
  |dfs.client.failover.connection.retries=0
  |dfs.client.failover.connection.retries.on.timeouts=0
  |dfs.client.failover.max.attempts=15
  |dfs.client.failover.sleep.base.millis=500
  |dfs.client.failover.sleep.max.millis=15000
  |dfs.client.file-block-storage-locations.num-threads=10
  |dfs.client.file-block-storage-locations.timeout.millis=1000
  |dfs.client.https.keystore.resource=ssl-client.xml
  |dfs.client.https.need-auth=false
  |dfs.client.mmap.cache.size=256
  |dfs.client.mmap.cache.timeout.ms=3600000
  |dfs.client.mmap.enabled=true
  |dfs.client.mmap.retry.timeout.ms=300000
  |dfs.client.read.shortcircuit=false
  |dfs.client.read.shortcircuit.skip.checksum=false
  |dfs.client.read.shortcircuit.streams.cache.expiry.ms=300000
  |dfs.client.read.shortcircuit.streams.cache.size=256
  |dfs.client.short.circuit.replica.stale.threshold.ms=1800000
  |dfs.client.slow.io.warning.threshold.ms=30000
  |dfs.client.socket.send.buffer.size=131072
  |dfs.client.use.datanode.hostname=false
  |dfs.client.use.legacy.blockreader=false
  |dfs.client.use.legacy.blockreader.local=false
  |dfs.client.write.exclude.nodes.cache.expiry.interval.millis=600000
  |dfs.data.transfer.server.tcpnodelay=true
  |dfs.datanode.address=0.0.0.0:50010
  |dfs.datanode.available-space-volume-choosing-policy.balanced-space-preference-fraction=0.75f
  |dfs.datanode.available-space-volume-choosing-policy.balanced-space-threshold=10737418240
  |dfs.datanode.balance.bandwidthPerSec=10485760
  |dfs.datanode.block-pinning.enabled=false
  |dfs.datanode.block.id.layout.upgrade.threads=12
  |dfs.datanode.bp-ready.timeout=20
  |dfs.datanode.cache.revocation.polling.ms=500
  |dfs.datanode.cache.revocation.timeout.ms=900000
  |dfs.datanode.data.dir=file://${hadoop.tmp.dir}/dfs/data
  |dfs.datanode.data.dir.perm=700
  |dfs.datanode.directoryscan.interval=21600
  |dfs.datanode.directoryscan.threads=1
  |dfs.datanode.directoryscan.throttle.limit.ms.per.sec=1000
  |dfs.datanode.dns.interface=default
  |dfs.datanode.dns.nameserver=default
  |dfs.datanode.drop.cache.behind.reads=false
  |dfs.datanode.drop.cache.behind.writes=false
  |dfs.datanode.du.reserved=0
  |dfs.datanode.failed.volumes.tolerated=0
  |dfs.datanode.fsdatasetcache.max.threads.per.volume=4
  |dfs.datanode.handler.count=10
  |dfs.datanode.hdfs-blocks-metadata.enabled=true
  |dfs.datanode.http.address=0.0.0.0:50075
  |dfs.datanode.https.address=0.0.0.0:50475
  |dfs.datanode.ipc.address=0.0.0.0:50020
  |dfs.datanode.max.locked.memory=0
  |dfs.datanode.max.transfer.threads=4096
  |dfs.datanode.readahead.bytes=4194304
  |dfs.datanode.scan.period.hours=504
  |dfs.datanode.shared.file.descriptor.paths=/dev/shm,/tmp
  |dfs.datanode.slow.io.warning.threshold.ms=300
  |dfs.datanode.sync.behind.writes=false
  |dfs.datanode.transfer.socket.recv.buffer.size=131072
  |dfs.datanode.transfer.socket.send.buffer.size=131072
  |dfs.datanode.use.datanode.hostname=false
  |dfs.default.chunk.view.size=32768
  |dfs.disk.balancer.block.tolerance.percent=10
  |dfs.disk.balancer.enabled=false
  |dfs.disk.balancer.max.disk.errors=5
  |dfs.disk.balancer.max.disk.throughputInMBperSec=10
  |dfs.disk.balancer.plan.threshold.percent=10
  |dfs.domain.socket.path=/var/run/hdfs-sockets/dn
  |dfs.encrypt.data.transfer=false
  |dfs.encrypt.data.transfer.cipher.key.bitlength=128
  |dfs.ha.automatic-failover.enabled=false
  |dfs.ha.fencing.ssh.connect-timeout=30000
  |dfs.ha.log-roll.period=120
  |dfs.ha.tail-edits.period=60
  |dfs.ha.tail-edits.rolledits.timeout=60
  |dfs.ha.zkfc.nn.http.timeout.ms=20000
  |dfs.heartbeat.interval=3
  |dfs.http.policy=HTTP_ONLY
  |dfs.https.port=50470
  |dfs.https.server.keystore.resource=ssl-server.xml
  |dfs.image.compress=false
  |dfs.image.compression.codec=org.apache.hadoop.io.compress.DefaultCodec
  |dfs.image.transfer-bootstrap-standby.bandwidthPerSec=0
  |dfs.image.transfer.bandwidthPerSec=0
  |dfs.image.transfer.chunksize=65536
  |dfs.image.transfer.timeout=60000
  |dfs.journalnode.http-address=0.0.0.0:8480
  |dfs.journalnode.https-address=0.0.0.0:8481
  |dfs.journalnode.rpc-address=0.0.0.0:8485
  |dfs.lock.suppress.warning.interval=10s
  |dfs.mover.max-no-move-interval=60000
  |dfs.namenode.accesstime.precision=3600000
  |dfs.namenode.acls.enabled=false
  |dfs.namenode.audit.loggers=default
  |dfs.namenode.avoid.read.stale.datanode=false
  |dfs.namenode.avoid.write.stale.datanode=false
  |dfs.namenode.backup.address=0.0.0.0:50100
  |dfs.namenode.backup.http-address=0.0.0.0:50105
  |dfs.namenode.block-placement-policy.default.prefer-local-node=true
  |dfs.namenode.blocks.per.postponedblocks.rescan=10000
  |dfs.namenode.checkpoint.check.period=60
  |dfs.namenode.checkpoint.dir=file://${hadoop.tmp.dir}/dfs/namesecondary
  |dfs.namenode.checkpoint.edits.dir=${dfs.namenode.checkpoint.dir}
  |dfs.namenode.checkpoint.max-retries=3
  |dfs.namenode.checkpoint.period=3600
  |dfs.namenode.checkpoint.txns=1000000
  |dfs.namenode.datanode.registration.ip-hostname-check=true
  |dfs.namenode.decommission.blocks.per.interval=500000
  |dfs.namenode.decommission.interval=30
  |dfs.namenode.decommission.max.concurrent.tracked.nodes=100
  |dfs.namenode.delegation.key.update-interval=86400000
  |dfs.namenode.delegation.token.max-lifetime=604800000
  |dfs.namenode.delegation.token.renew-interval=86400000
  |dfs.namenode.edekcacheloader.initial.delay.ms=3000
  |dfs.namenode.edekcacheloader.interval.ms=1000
  |dfs.namenode.edit.log.autoroll.check.interval.ms=300000
  |dfs.namenode.edit.log.autoroll.multiplier.threshold=2.0
  |dfs.namenode.edits.dir=${dfs.namenode.name.dir}
  |dfs.namenode.edits.journal-plugin.qjournal=org.apache.hadoop.hdfs.qjournal.client.QuorumJournalManager
  |dfs.namenode.edits.noeditlogchannelflush=false
  |dfs.namenode.enable.retrycache=true
  |dfs.namenode.fs-limits.max-blocks-per-file=1048576
  |dfs.namenode.fs-limits.max-component-length=255
  |dfs.namenode.fs-limits.max-directory-items=1048576
  |dfs.namenode.fs-limits.max-xattr-size=16384
  |dfs.namenode.fs-limits.max-xattrs-per-inode=32
  |dfs.namenode.fs-limits.min-block-size=1048576
  |dfs.namenode.fslock.fair=true
  |dfs.namenode.full.block.report.lease.length.ms=300000
  |dfs.namenode.handler.count=10
  |dfs.namenode.hosts.provider.classname=org.apache.hadoop.hdfs.server.blockmanagement.HostFileManager
  |dfs.namenode.http-address=quickstart.cloudera:50070
  |dfs.namenode.https-address=quickstart.cloudera:50470
  |dfs.namenode.inotify.max.events.per.rpc=1000
  |dfs.namenode.invalidate.work.pct.per.iteration=0.32f
  |dfs.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}
  |dfs.namenode.kerberos.principal.pattern=*
  |dfs.namenode.lazypersist.file.scrub.interval.sec=300
  |dfs.namenode.lease-recheck-interval-ms=2000
  |dfs.namenode.list.cache.directives.num.responses=100
  |dfs.namenode.list.cache.pools.num.responses=100
  |dfs.namenode.list.encryption.zones.num.responses=100
  |dfs.namenode.list.openfiles.num.responses=1000
  |dfs.namenode.list.reencryption.status.num.responses=100
  |dfs.namenode.maintenance.replication.min=1
  |dfs.namenode.max-lock-hold-to-release-lease-ms=25
  |dfs.namenode.max.extra.edits.segments.retained=10000
  |dfs.namenode.max.full.block.report.leases=6
  |dfs.namenode.max.objects=0
  |dfs.namenode.name.dir=file:///var/lib/hadoop-hdfs/cache/hdfs/dfs/name
  |dfs.namenode.name.dir.restore=false
  |dfs.namenode.num.checkpoints.retained=2
  |dfs.namenode.num.extra.edits.retained=1000000
  |dfs.namenode.path.based.cache.block.map.allocation.percent=0.25
  |dfs.namenode.path.based.cache.refresh.interval.ms=30000
  |dfs.namenode.path.based.cache.retry.interval.ms=30000
  |dfs.namenode.posix.acl.inheritance.enabled=false
  |dfs.namenode.read-lock-reporting-threshold-ms=5000
  |dfs.namenode.reencrypt.batch.size=1000
  |dfs.namenode.reencrypt.edek.threads=10
  |dfs.namenode.reencrypt.sleep.interval=1m
  |dfs.namenode.reencrypt.throttle.limit.handler.ratio=1.0
  |dfs.namenode.reencrypt.throttle.limit.updater.ratio=1.0
  |dfs.namenode.reject-unresolved-dn-topology-mapping=false
  |dfs.namenode.replication.considerLoad=true
  |dfs.namenode.replication.interval=3
  |dfs.namenode.replication.min=1
  |dfs.namenode.replication.work.multiplier.per.iteration=2
  |dfs.namenode.resource.check.interval=5000
  |dfs.namenode.resource.checked.volumes.minimum=1
  |dfs.namenode.resource.du.reserved=104857600
  |dfs.namenode.retrycache.expirytime.millis=600000
  |dfs.namenode.retrycache.heap.percent=0.03f
  |dfs.namenode.safemode.extension=30000
  |dfs.namenode.safemode.min.datanodes=0
  |dfs.namenode.safemode.threshold-pct=0.999f
  |dfs.namenode.secondary.http-address=0.0.0.0:50090
  |dfs.namenode.secondary.https-address=0.0.0.0:50091
  |dfs.namenode.service.handler.count=10
  |dfs.namenode.servicerpc-address=quickstart.cloudera:8022
  |dfs.namenode.snapshot.capture.openfiles=false
  |dfs.namenode.snapshot.skip.capture.accesstime-only-change=false
  |dfs.namenode.stale.datanode.interval=30000
  |dfs.namenode.startup.delay.block.deletion.sec=0
  |dfs.namenode.support.allow.format=true
  |dfs.namenode.top.enabled=true
  |dfs.namenode.top.num.users=10
  |dfs.namenode.top.window.num.buckets=10
  |dfs.namenode.top.windows.minutes=1,5,25
  |dfs.namenode.write-lock-reporting-threshold-ms=5000
  |dfs.namenode.write.stale.datanode.ratio=0.5f
  |dfs.namenode.xattrs.enabled=true
  |dfs.permissions.enabled=true
  |dfs.permissions.superusergroup=supergroup
  |dfs.replication=1
  |dfs.replication.max=512
  |dfs.secondary.namenode.kerberos.internal.spnego.principal=${dfs.web.authentication.kerberos.principal}
  |dfs.short.circuit.shared.memory.watcher.interrupt.check.ms=60000
  |dfs.storage.policy.enabled=true
  |dfs.stream-buffer-size=4096
  |dfs.user.home.dir.prefix=/user
  |dfs.webhdfs.acl.provider.permission.pattern=^(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?(,(default:)?(user|group|mask|other):[[A-Za-z_][A-Za-z0-9._-]]*:([rwx-]{3})?)*$
  |dfs.webhdfs.enabled=true
  |dfs.webhdfs.ugi.expire.after.access=600000
  |dfs.webhdfs.user.provider.user.pattern=^[A-Za-z_][A-Za-z0-9._-]*[$]?$
  |file.blocksize=67108864
  |file.bytes-per-checksum=512
  |file.client-write-packet-size=65536
  |file.replication=1
  |file.stream-buffer-size=4096
  |fs.AbstractFileSystem.adl.impl=org.apache.hadoop.fs.adl.Adl
  |fs.AbstractFileSystem.file.impl=org.apache.hadoop.fs.local.LocalFs
  |fs.AbstractFileSystem.har.impl=org.apache.hadoop.fs.HarFs
  |fs.AbstractFileSystem.hdfs.impl=org.apache.hadoop.fs.Hdfs
  |fs.AbstractFileSystem.s3a.impl=org.apache.hadoop.fs.s3a.S3A
  |fs.AbstractFileSystem.viewfs.impl=org.apache.hadoop.fs.viewfs.ViewFs
  |fs.adl.impl=org.apache.hadoop.fs.adl.AdlFileSystem
  |fs.adl.oauth2.access.token.provider.type=ClientCredential
  |fs.automatic.close=true
  |fs.client.resolve.remote.symlinks=true
  |fs.defaultFS=hdfs://quickstart.cloudera:8020
  |fs.df.interval=60000
  |fs.du.interval=600000
  |fs.ftp.data.connection.mode=ACTIVE_LOCAL_DATA_CONNECTION_MODE
  |fs.ftp.host=0.0.0.0
  |fs.ftp.host.port=21
  |fs.ftp.transfer.mode=BLOCK_TRANSFER_MODE
  |fs.har.impl=org.apache.hadoop.hive.shims.HiveHarFileSystem
  |fs.har.impl.disable.cache=true
  |fs.permissions.umask-mode=022
  |fs.s3.block.size=67108864
  |fs.s3.buffer.dir=${hadoop.tmp.dir}/s3
  |fs.s3.maxRetries=4
  |fs.s3.sleepTimeSeconds=10
  |fs.s3a.attempts.maximum=20
  |fs.s3a.block.size=32M
  |fs.s3a.buffer.dir=${hadoop.tmp.dir}/s3a
  |fs.s3a.connection.establish.timeout=5000
  |fs.s3a.connection.maximum=100
  |fs.s3a.connection.ssl.enabled=true
  |fs.s3a.connection.timeout=200000
  |fs.s3a.fast.upload=false
  |fs.s3a.fast.upload.active.blocks=4
  |fs.s3a.fast.upload.buffer=disk
  |fs.s3a.impl=org.apache.hadoop.fs.s3a.S3AFileSystem
  |fs.s3a.max.total.tasks=5
  |fs.s3a.metadatastore.authoritative=false
  |fs.s3a.metadatastore.impl=org.apache.hadoop.fs.s3a.s3guard.NullMetadataStore
  |fs.s3a.multiobjectdelete.enable=true
  |fs.s3a.multipart.purge=false
  |fs.s3a.multipart.purge.age=86400
  |fs.s3a.multipart.size=64M
  |fs.s3a.multipart.threshold=128M
  |fs.s3a.paging.maximum=5000
  |fs.s3a.path.style.access=false
  |fs.s3a.readahead.range=64K
  |fs.s3a.s3guard.cli.prune.age=86400000
  |fs.s3a.s3guard.ddb.background.sleep=25
  |fs.s3a.s3guard.ddb.max.retries=9
  |fs.s3a.s3guard.ddb.table.capacity.read=500
  |fs.s3a.s3guard.ddb.table.capacity.write=100
  |fs.s3a.s3guard.ddb.table.create=false
  |fs.s3a.socket.recv.buffer=8192
  |fs.s3a.socket.send.buffer=8192
  |fs.s3a.threads.keepalivetime=60
  |fs.s3a.threads.max=10
  |fs.s3n.block.size=67108864
  |fs.s3n.multipart.copy.block.size=5368709120
  |fs.s3n.multipart.uploads.block.size=67108864
  |fs.s3n.multipart.uploads.enabled=false
  |fs.scheme.class=dfs
  |fs.swift.impl=org.apache.hadoop.fs.swift.snative.SwiftNativeFileSystem
  |fs.trash.checkpoint.interval=0
  |fs.trash.interval=1
  |ftp.blocksize=67108864
  |ftp.bytes-per-checksum=512
  |ftp.client-write-packet-size=65536
  |ftp.replication=3
  |ftp.stream-buffer-size=4096
  |ha.failover-controller.cli-check.rpc-timeout.ms=20000
  |ha.failover-controller.graceful-fence.connection.retries=1
  |ha.failover-controller.graceful-fence.rpc-timeout.ms=5000
  |ha.failover-controller.new-active.rpc-timeout.ms=60000
  |ha.health-monitor.check-interval.ms=1000
  |ha.health-monitor.connect-retry-interval.ms=1000
  |ha.health-monitor.rpc-timeout.ms=45000
  |ha.health-monitor.sleep-after-disconnect.ms=1000
  |ha.zookeeper.acl=world:anyone:rwcda
  |ha.zookeeper.parent-znode=/hadoop-ha
  |ha.zookeeper.session-timeout.ms=5000
  |hadoop.bin.path=/usr/lib/hadoop/bin/hadoop
  |hadoop.common.configuration.version=0.23.0
  |hadoop.fuse.connection.timeout=300
  |hadoop.fuse.timer.period=5
  |hadoop.hdfs.configuration.version=1
  |hadoop.http.authentication.kerberos.keytab=${user.home}/hadoop.keytab
  |hadoop.http.authentication.kerberos.principal=HTTP/_HOST@LOCALHOST
  |hadoop.http.authentication.signature.secret.file=${user.home}/hadoop-http-auth-signature-secret
  |hadoop.http.authentication.simple.anonymous.allowed=true
  |hadoop.http.authentication.token.validity=36000
  |hadoop.http.authentication.type=simple
  |hadoop.http.filter.initializers=org.apache.hadoop.http.lib.StaticUserWebFilter
  |hadoop.http.logs.enabled=true
  |hadoop.http.staticuser.user=dr.who
  |hadoop.jetty.logs.serve.aliases=true
  |hadoop.kerberos.kinit.command=kinit
  |hadoop.kerberos.min.seconds.before.relogin=60
  |hadoop.proxyuser.HTTP.groups=*
  |hadoop.proxyuser.HTTP.hosts=*
  |hadoop.proxyuser.flume.groups=*
  |hadoop.proxyuser.flume.hosts=*
  |hadoop.proxyuser.hdfs.groups=*
  |hadoop.proxyuser.hdfs.hosts=*
  |hadoop.proxyuser.hive.groups=*
  |hadoop.proxyuser.hive.hosts=*
  |hadoop.proxyuser.httpfs.groups=*
  |hadoop.proxyuser.httpfs.hosts=*
  |hadoop.proxyuser.hue.groups=*
  |hadoop.proxyuser.hue.hosts=*
  |hadoop.proxyuser.mapred.groups=*
  |hadoop.proxyuser.mapred.hosts=*
  |hadoop.proxyuser.oozie.groups=*
  |hadoop.proxyuser.oozie.hosts=*
  |hadoop.proxyuser.yarn.groups=*
  |hadoop.proxyuser.yarn.hosts=*
  |hadoop.registry.jaas.context=Client
  |hadoop.registry.rm.enabled=false
  |hadoop.registry.secure=false
  |hadoop.registry.system.acls=sasl:yarn@, sasl:mapred@, sasl:mapred@hdfs@
  |hadoop.registry.zk.connection.timeout.ms=15000
  |hadoop.registry.zk.quorum=localhost:2181
  |hadoop.registry.zk.retry.ceiling.ms=60000
  |hadoop.registry.zk.retry.interval.ms=1000
  |hadoop.registry.zk.retry.times=5
  |hadoop.registry.zk.root=/registry
  |hadoop.registry.zk.session.timeout.ms=60000
  |hadoop.rpc.protection=authentication
  |hadoop.rpc.socket.factory.class.default=org.apache.hadoop.net.StandardSocketFactory
  |hadoop.security.auth_to_local=DEFAULT
  |hadoop.security.authentication=simple
  |hadoop.security.authorization=false
  |hadoop.security.credential.clear-text-fallback=true
  |hadoop.security.crypto.buffer.size=8192
  |hadoop.security.crypto.cipher.suite=AES/CTR/NoPadding
  |hadoop.security.crypto.codec.classes.aes.ctr.nopadding=org.apache.hadoop.crypto.OpensslAesCtrCryptoCodec,org.apache.hadoop.crypto.JceAesCtrCryptoCodec
  |hadoop.security.dns.log-slow-lookups.enabled=false
  |hadoop.security.dns.log-slow-lookups.threshold.ms=1000
  |hadoop.security.group.mapping=org.apache.hadoop.security.ShellBasedUnixGroupsMapping
  |hadoop.security.group.mapping.ldap.directory.search.timeout=10000
  |hadoop.security.group.mapping.ldap.posix.attr.gid.name=gidNumber
  |hadoop.security.group.mapping.ldap.posix.attr.uid.name=uidNumber
  |hadoop.security.group.mapping.ldap.search.attr.group.name=cn
  |hadoop.security.group.mapping.ldap.search.attr.member=member
  |hadoop.security.group.mapping.ldap.search.filter.group=(objectClass=group)
  |hadoop.security.group.mapping.ldap.search.filter.user=(&(objectClass=user)(sAMAccountName={0}))
  |hadoop.security.group.mapping.ldap.ssl=false
  |hadoop.security.groups.cache.background.reload=false
  |hadoop.security.groups.cache.background.reload.threads=3
  |hadoop.security.groups.cache.secs=300
  |hadoop.security.groups.cache.warn.after.ms=5000
  |hadoop.security.groups.negative-cache.secs=30
  |hadoop.security.instrumentation.requires.admin=false
  |hadoop.security.java.secure.random.algorithm=SHA1PRNG
  |hadoop.security.kms.client.authentication.retry-count=1
  |hadoop.security.kms.client.encrypted.key.cache.expiry=43200000
  |hadoop.security.kms.client.encrypted.key.cache.low-watermark=0.3f
  |hadoop.security.kms.client.encrypted.key.cache.num.refill.threads=2
  |hadoop.security.kms.client.encrypted.key.cache.size=500
  |hadoop.security.random.device.file.path=/dev/urandom
  |hadoop.security.sensitive-config-keys=
  |      secret$
  |      password$
  |      ssl.keystore.pass$
  |      fs.s3.*[Ss]ecret.?[Kk]ey
  |      fs.s3a.*.server-side-encryption.key
  |      fs.azure.account.key.*
  |      credential$
  |      oauth.*token$
  |      hadoop.security.sensitive-config-keys
  |
  |hadoop.security.uid.cache.secs=14400
  |hadoop.shell.missing.defaultFs.warning=true
  |hadoop.ssl.client.conf=ssl-client.xml
  |hadoop.ssl.enabled=false
  |hadoop.ssl.enabled.protocols=TLSv1,SSLv2Hello,TLSv1.1,TLSv1.2
  |hadoop.ssl.hostname.verifier=DEFAULT
  |hadoop.ssl.keystores.factory.class=org.apache.hadoop.security.ssl.FileBasedKeyStoresFactory
  |hadoop.ssl.require.client.cert=false
  |hadoop.ssl.server.conf=ssl-server.xml
  |hadoop.tmp.dir=/tmp/hadoop-${user.name}
  |hadoop.user.group.static.mapping.overrides=dr.who=;
  |hadoop.util.hash.type=murmur
  |hadoop.work.around.non.threadsafe.getpwuid=false
  |hive.analyze.stmt.collect.partlevel.stats=true
  |hive.archive.enabled=false
  |hive.auto.convert.join=true
  |hive.auto.convert.join.noconditionaltask=true
  |hive.auto.convert.join.noconditionaltask.size=20971520
  |hive.auto.convert.join.use.nonstaged=false
  |hive.auto.convert.sortmerge.join=false
  |hive.auto.convert.sortmerge.join.bigtable.selection.policy=org.apache.hadoop.hive.ql.optimizer.AvgPartitionSizeBasedBigTableSelectorForAutoSMJ
  |hive.auto.convert.sortmerge.join.to.mapjoin=false
  |hive.auto.progress.timeout=0s
  |hive.autogen.columnalias.prefix.includefuncname=false
  |hive.autogen.columnalias.prefix.label=_c
  |hive.binary.record.max.length=1000
  |hive.blobstore.optimizations.enabled=true
  |hive.blobstore.supported.schemes=s3,s3a,s3n
  |hive.blobstore.use.blobstore.as.scratchdir=false
  |hive.cache.expr.evaluation=true
  |hive.cbo.enable=false
  |hive.cli.errors.ignore=false
  |hive.cli.pretty.output.num.cols=-1
  |hive.cli.print.current.db=false
  |hive.cli.print.header=false
  |hive.cli.prompt=hive
  |hive.cluster.delegation.token.store.class=org.apache.hadoop.hive.thrift.MemoryTokenStore
  |hive.cluster.delegation.token.store.zookeeper.znode=/hivedelegation
  |hive.compactor.abortedtxn.threshold=1000
  |hive.compactor.check.interval=300s
  |hive.compactor.cleaner.run.interval=5000ms
  |hive.compactor.delta.num.threshold=10
  |hive.compactor.delta.pct.threshold=0.1
  |hive.compactor.initiator.on=false
  |hive.compactor.worker.threads=0
  |hive.compactor.worker.timeout=86400s
  |hive.compat=0.12
  |hive.compute.query.using.stats=false
  |hive.compute.splits.in.am=true
  |hive.conf.hidden.list=javax.jdo.option.ConnectionPassword,hive.server2.keystore.password,fs.s3.awsAccessKeyId,fs.s3.awsSecretAccessKey,fs.s3n.awsAccessKeyId,fs.s3n.awsSecretAccessKey,fs.s3a.access.key,fs.s3a.secret.key,fs.s3a.proxy.password
  |hive.conf.restricted.list=hive.security.authenticator.manager,hive.security.authorization.manager,hive.users.in.admin.role
  |hive.conf.validation=true
  |hive.convert.join.bucket.mapjoin.tez=false
  |hive.counters.group.name=HIVE
  |hive.debug.localtask=false
  |hive.decode.partition.name=false
  |hive.default.fileformat=TextFile
  |hive.default.rcfile.serde=org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe
  |hive.default.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
  |hive.display.partition.cols.separately=true
  |hive.downloaded.resources.dir=/tmp/${hive.session.id}_resources
  |hive.enforce.bucketing=false
  |hive.enforce.bucketmapjoin=false
  |hive.enforce.sorting=false
  |hive.enforce.sortmergebucketmapjoin=false
  |hive.entity.capture.transform=false
  |hive.entity.separator=@
  |hive.error.on.empty.partition=false
  |hive.exec.check.crossproducts=true
  |hive.exec.compress.intermediate=false
  |hive.exec.compress.output=false
  |hive.exec.concatenate.check.index=true
  |hive.exec.copyfile.maxsize=33554432
  |hive.exec.counters.pull.interval=1000
  |hive.exec.default.partition.name=__HIVE_DEFAULT_PARTITION__
  |hive.exec.drop.ignorenonexistent=true
  |hive.exec.dynamic.partition=true
  |hive.exec.dynamic.partition.mode=strict
  |hive.exec.infer.bucket.sort=false
  |hive.exec.infer.bucket.sort.num.buckets.power.two=false
  |hive.exec.input.listing.max.threads=0
  |hive.exec.job.debug.capture.stacktraces=true
  |hive.exec.job.debug.timeout=30000
  |hive.exec.local.scratchdir=/tmp/cloudera
  |hive.exec.max.created.files=100000
  |hive.exec.max.dynamic.partitions=1000
  |hive.exec.max.dynamic.partitions.pernode=100
  |hive.exec.mode.local.auto=false
  |hive.exec.mode.local.auto.input.files.max=4
  |hive.exec.mode.local.auto.inputbytes.max=134217728
  |hive.exec.orc.block.padding.tolerance=0.05
  |hive.exec.orc.compression.strategy=SPEED
  |hive.exec.orc.default.block.padding=true
  |hive.exec.orc.default.block.size=268435456
  |hive.exec.orc.default.buffer.size=262144
  |hive.exec.orc.default.compress=ZLIB
  |hive.exec.orc.default.row.index.stride=10000
  |hive.exec.orc.default.stripe.size=67108864
  |hive.exec.orc.dictionary.key.size.threshold=0.8
  |hive.exec.orc.encoding.strategy=SPEED
  |hive.exec.orc.memory.pool=0.5
  |hive.exec.orc.skip.corrupt.data=false
  |hive.exec.orc.zerocopy=false
  |hive.exec.parallel=false
  |hive.exec.parallel.thread.number=8
  |hive.exec.perf.logger=org.apache.hadoop.hive.ql.log.PerfLogger
  |hive.exec.rcfile.use.explicit.header=true
  |hive.exec.rcfile.use.sync.cache=true
  |hive.exec.reducers.bytes.per.reducer=67108864
  |hive.exec.reducers.max=1099
  |hive.exec.rowoffset=false
  |hive.exec.scratchdir=file:/tmp/spark-7a09d126-987b-45d1-b5a6-d2c3d5a8dca5/scratch
  |hive.exec.script.allow.partial.consumption=false
  |hive.exec.script.maxerrsize=100000
  |hive.exec.script.trust=false
  |hive.exec.show.job.failure.debug.info=true
  |hive.exec.stagingdir=.hive-staging
  |hive.exec.submit.local.task.via.child=true
  |hive.exec.submitviachild=false
  |hive.exec.tasklog.debug.timeout=20000
  |hive.execution.engine=mr
  |hive.exim.strict.repl.tables=true
  |hive.exim.uri.scheme.whitelist=hdfs,pfile,s3,s3a,adl
  |hive.explain.dependency.append.tasktype=false
  |hive.fetch.output.serde=org.apache.hadoop.hive.serde2.DelimitedJSONSerDe
  |hive.fetch.task.aggr=false
  |hive.fetch.task.conversion=minimal
  |hive.fetch.task.conversion.threshold=268435456
  |hive.file.max.footer=100
  |hive.fileformat.check=true
  |hive.groupby.mapaggr.checkinterval=100000
  |hive.groupby.orderby.position.alias=false
  |hive.groupby.skewindata=false
  |hive.hashtable.initialCapacity=100000
  |hive.hashtable.key.count.adjustment=1.0
  |hive.hashtable.loadfactor=0.75
  |hive.hbase.generatehfiles=false
  |hive.hbase.snapshot.restoredir=/tmp
  |hive.hbase.wal.enabled=true
  |hive.heartbeat.interval=1000
  |hive.hmshandler.force.reload.conf=false
  |hive.hmshandler.retry.attempts=10
  |hive.hmshandler.retry.interval=2000ms
  |hive.hwi.listen.host=0.0.0.0
  |hive.hwi.listen.port=9999
  |hive.hwi.war.file=${env:HWI_WAR_FILE}
  |hive.ignore.mapjoin.hint=true
  |hive.in.test=false
  |hive.in.test.remove.logs=true
  |hive.in.test.short.logs=false
  |hive.in.tez.test=false
  |hive.index.compact.binary.search=true
  |hive.index.compact.file.ignore.hdfs=false
  |hive.index.compact.query.max.entries=10000000
  |hive.index.compact.query.max.size=10737418240
  |hive.input.format=org.apache.hadoop.hive.ql.io.CombineHiveInputFormat
  |hive.insert.into.external.tables=true
  |hive.insert.into.multilevel.dirs=false
  |hive.io.rcfile.column.number.conf=0
  |hive.io.rcfile.record.buffer.size=4194304
  |hive.io.rcfile.record.interval=2147483647
  |hive.io.rcfile.tolerate.corruptions=false
  |hive.jobname.length=50
  |hive.join.cache.size=25000
  |hive.join.emit.interval=1000
  |hive.lazysimple.extended_boolean_literal=false
  |hive.limit.optimize.enable=false
  |hive.limit.optimize.fetch.max=50000
  |hive.limit.optimize.limit.file=10
  |hive.limit.pushdown.memory.usage=0.1
  |hive.limit.query.max.table.partition=-1
  |hive.limit.row.max.size=100000
  |hive.load.dynamic.partitions.thread=15
  |hive.localize.resource.num.wait.attempts=5
  |hive.localize.resource.wait.interval=5000ms
  |hive.lock.manager=org.apache.hadoop.hive.ql.lockmgr.zookeeper.ZooKeeperHiveLockManager
  |hive.lock.mapred.only.operation=false
  |hive.lock.numretries=100
  |hive.lock.query.string.max.length=1000000
  |hive.lock.sleep.between.retries=60s
  |hive.lockmgr.zookeeper.default.partition.name=__HIVE_DEFAULT_ZOOKEEPER_PARTITION__
  |hive.log.explain.output=false
  |hive.map.aggr=true
  |hive.map.aggr.hash.force.flush.memory.threshold=0.9
  |hive.map.aggr.hash.min.reduction=0.5
  |hive.map.aggr.hash.percentmemory=0.5
  |hive.map.groupby.sorted=false
  |hive.map.groupby.sorted.testmode=false
  |hive.mapjoin.bucket.cache.size=100
  |hive.mapjoin.check.memory.rows=100000
  |hive.mapjoin.followby.gby.localtask.max.memory.usage=0.55
  |hive.mapjoin.followby.map.aggr.hash.percentmemory=0.3
  |hive.mapjoin.localtask.max.memory.usage=0.9
  |hive.mapjoin.optimized.hashtable=true
  |hive.mapjoin.optimized.hashtable.wbsize=10485760
  |hive.mapjoin.smalltable.filesize=25000000
  |hive.mapper.cannot.span.multiple.partitions=false
  |hive.mapred.local.mem=0
  |hive.mapred.mode=nonstrict
  |hive.mapred.partitioner=org.apache.hadoop.hive.ql.io.DefaultHivePartitioner
  |hive.mapred.reduce.tasks.speculative.execution=true
  |hive.mapred.supports.subdirectories=false
  |hive.merge.mapfiles=true
  |hive.merge.mapredfiles=false
  |hive.merge.orcfile.stripe.level=true
  |hive.merge.rcfile.block.level=true
  |hive.merge.size.per.task=268435456
  |hive.merge.smallfiles.avgsize=16777216
  |hive.merge.sparkfiles=true
  |hive.merge.tezfiles=false
  |hive.metadata.move.exported.metadata.to.trash=true
  |hive.metastore.archive.intermediate.archived=_INTERMEDIATE_ARCHIVED
  |hive.metastore.archive.intermediate.extracted=_INTERMEDIATE_EXTRACTED
  |hive.metastore.archive.intermediate.original=_INTERMEDIATE_ORIGINAL
  |hive.metastore.authorization.storage.checks=false
  |hive.metastore.batch.retrieve.max=300
  |hive.metastore.batch.retrieve.table.partition.max=1000
  |hive.metastore.cache.pinobjtypes=Table,StorageDescriptor,SerDeInfo,Partition,Database,Type,FieldSchema,Order
  |hive.metastore.client.connect.retry.delay=1s
  |hive.metastore.client.socket.timeout=300
  |hive.metastore.connect.retries=3
  |hive.metastore.direct.sql.batch.size=0
  |hive.metastore.disallow.incompatible.col.type.changes=false
  |hive.metastore.dml.events=false
  |hive.metastore.end.function.listeners=
  |hive.metastore.event.clean.freq=0s
  |hive.metastore.event.db.listener.timetolive=86400s
  |hive.metastore.event.expiry.duration=0s
  |hive.metastore.event.listeners=
  |hive.metastore.execute.setugi=true
  |hive.metastore.expression.proxy=org.apache.hadoop.hive.ql.optimizer.ppr.PartitionExpressionForMetastore
  |hive.metastore.failure.retries=1
  |hive.metastore.filter.hook=org.apache.hadoop.hive.metastore.DefaultMetaStoreFilterHookImpl
  |hive.metastore.fs.handler.class=org.apache.hadoop.hive.metastore.HiveMetaStoreFsImpl
  |hive.metastore.fshandler.threads=15
  |hive.metastore.initial.metadata.count.enabled=true
  |hive.metastore.integral.jdo.pushdown=false
  |hive.metastore.kerberos.principal=hive-metastore/_HOST@EXAMPLE.COM
  |hive.metastore.limit.partition.request=-1
  |hive.metastore.metrics.enabled=false
  |hive.metastore.orm.retrieveMapNullsAsEmptyStrings=false
  |hive.metastore.pre.event.listeners=
  |hive.metastore.rawstore.impl=org.apache.hadoop.hive.metastore.ObjectStore
  |hive.metastore.sasl.enabled=false
  |hive.metastore.schema.info.class=org.apache.hadoop.hive.metastore.CDHMetaStoreSchemaInfo
  |hive.metastore.schema.verification=false
  |hive.metastore.schema.verification.record.version=true
  |hive.metastore.server.max.message.size=104857600
  |hive.metastore.server.max.threads=1000
  |hive.metastore.server.min.threads=200
  |hive.metastore.server.tcp.keepalive=true
  |hive.metastore.thrift.compact.protocol.enabled=false
  |hive.metastore.thrift.framed.transport.enabled=false
  |hive.metastore.try.direct.sql=true
  |hive.metastore.try.direct.sql.ddl=true
  |hive.metastore.uris=
  |hive.metastore.use.SSL=false
  |hive.metastore.warehouse.dir=file:/tmp/spark-7a09d126-987b-45d1-b5a6-d2c3d5a8dca5/metastore
  |hive.msck.path.validation=throw
  |hive.msck.repair.batch.size=0
  |hive.multi.insert.move.tasks.share.dependencies=false
  |hive.multigroupby.singlereducer=true
  |hive.mv.files.thread=15
  |hive.new.job.grouping.set.cardinality=30
  |hive.optimize.bucketingsorting=true
  |hive.optimize.bucketmapjoin=false
  |hive.optimize.bucketmapjoin.sortedmerge=false
  |hive.optimize.constant.propagation=true
  |hive.optimize.correlation=false
  |hive.optimize.distinct.rewrite=true
  |hive.optimize.groupby=true
  |hive.optimize.index.autoupdate=false
  |hive.optimize.index.filter=false
  |hive.optimize.index.filter.compact.maxsize=-1
  |hive.optimize.index.filter.compact.minsize=5368709120
  |hive.optimize.index.groupby=false
  |hive.optimize.listbucketing=false
  |hive.optimize.metadataonly=true
  |hive.optimize.null.scan=true
  |hive.optimize.ppd=true
  |hive.optimize.ppd.storage=true
  |hive.optimize.reducededuplication=true
  |hive.optimize.reducededuplication.min.reducer=4
  |hive.optimize.remove.identity.project=true
  |hive.optimize.sampling.orderby=false
  |hive.optimize.sampling.orderby.number=1000
  |hive.optimize.sampling.orderby.percent=0.1
  |hive.optimize.skewjoin=false
  |hive.optimize.skewjoin.compiletime=false
  |hive.optimize.sort.dynamic.partition=false
  |hive.optimize.union.remove=false
  |hive.orc.cache.stripe.details.size=10000
  |hive.orc.compute.splits.num.threads=10
  |hive.orc.row.index.stride.dictionary.check=true
  |hive.orc.splits.include.file.footer=false
  |hive.outerjoin.supports.filters=true
  |hive.parquet.timestamp.skip.conversion=true
  |hive.plan.serialization.format=kryo
  |hive.ppd.recognizetransivity=true
  |hive.ppd.remove.duplicatefilters=true
  |hive.prewarm.enabled=false
  |hive.prewarm.numcontainers=10
  |hive.query.result.fileformat=TextFile
  |hive.query.timeout.seconds=0s
  |hive.querylog.enable.plan.progress=true
  |hive.querylog.location=/tmp/cloudera
  |hive.querylog.plan.progress.interval=60000ms
  |hive.reorder.nway.joins=true
  |hive.resultset.use.unique.column.names=true
  |hive.rework.mapredwork=false
  |hive.rpc.query.plan=false
  |hive.sample.seednumber=0
  |hive.scratch.dir.permission=700
  |hive.scratchdir.lock=false
  |hive.script.auto.progress=false
  |hive.script.operator.env.blacklist=hive.txn.valid.txns,hive.script.operator.env.blacklist
  |hive.script.operator.id.env.var=HIVE_SCRIPT_OPERATOR_ID
  |hive.script.operator.truncate.env=false
  |hive.script.recordreader=org.apache.hadoop.hive.ql.exec.TextRecordReader
  |hive.script.recordwriter=org.apache.hadoop.hive.ql.exec.TextRecordWriter
  |hive.script.serde=org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe
  |hive.security.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultAuthenticator
  |hive.security.authorization.enabled=false
  |hive.security.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveAuthorizationProvider
  |hive.security.authorization.sqlstd.confwhitelist=hive\.auto\..*|hive\.cbo\..*|hive\.convert\..*|hive\.exec\.dynamic\.partition.*|hive\.exec\..*\.dynamic\.partitions\..*|hive\.exec\.compress\..*|hive\.exec\.infer\..*|hive\.exec\.mode.local\..*|hive\.exec\.orc\..*|hive\.fetch.task\..*|hive\.hbase\..*|hive\.index\..*|hive\.index\..*|hive\.intermediate\..*|hive\.join\..*|hive\.limit\..*|hive\.mapjoin\..*|hive\.merge\..*|hive\.optimize\..*|hive\.orc\..*|hive\.outerjoin\..*|hive\.ppd\..*|hive\.prewarm\..*|hive\.skewjoin\..*|hive\.smbjoin\..*|hive\.stats\..*|hive\.tez\..*|hive\.vectorized\..*|mapred\.map\..*|mapred\.reduce\..*|mapred\.output\.compression\.codec|mapreduce\.job\.reduce\.slowstart\.completedmaps|mapreduce\.job\.queuename|mapreduce\.input\.fileinputformat\.split\.minsize|mapreduce\.map\..*|mapreduce\.reduce\..*|tez\.am\..*|tez\.task\..*|tez\.runtime\..*|hive\.exec\.reducers\.bytes\.per\.reducer|hive\.client\.stats\.counters|hive\.exec\.default\.partition\.name|hive\.exec\.drop\.ignorenonexistent|hive\.counters\.group\.name|hive\.enforce\.bucketing|hive\.enforce\.bucketmapjoin|hive\.enforce\.sorting|hive\.enforce\.sortmergebucketmapjoin|hive\.cache\.expr\.evaluation|hive\.groupby\.skewindata|hive\.hashtable\.loadfactor|hive\.hashtable\.initialCapacity|hive\.ignore\.mapjoin\.hint|hive\.limit\.row\.max\.size|hive\.mapred\.mode|hive\.map\.aggr|hive\.compute\.query\.using\.stats|hive\.exec\.rowoffset|hive\.variable\.substitute|hive\.variable\.substitute\.depth|hive\.autogen\.columnalias\.prefix\.includefuncname|hive\.autogen\.columnalias\.prefix\.label|hive\.exec\.check\.crossproducts|hive\.compat|hive\.exec\.concatenate\.check\.index|hive\.display\.partition\.cols\.separately|hive\.error\.on\.empty\.partition|hive\.execution\.engine|hive\.exim\.uri\.scheme\.whitelist|hive\.file\.max\.footer|hive\.mapred\.supports\.subdirectories|hive\.insert\.into\.multilevel\.dirs|hive\.localize\.resource\.num\.wait\.attempts|hive\.multi\.insert\.move\.tasks\.share\.dependencies|hive\.support\.quoted\.identifiers|hive\.resultset\.use\.unique\.column\.names|hive\.analyze\.stmt\.collect\.partlevel\.stats|hive\.exec\.job\.debug\.capture\.stacktraces|hive\.exec\.job\.debug\.timeout|hive\.exec\.max\.created\.files|hive\.exec\.reducers\.max|hive\.output\.file\.extension|hive\.exec\.show\.job\.failure\.debug\.info|hive\.exec\.tasklog\.debug\.timeout|hive\.query\.id
  |hive.security.authorization.task.factory=org.apache.hadoop.hive.ql.parse.authorization.RestrictedHiveAuthorizationTaskFactoryImpl
  |hive.security.command.whitelist=set,reset,dfs,add,list,delete,reload,compile
  |hive.security.metastore.authenticator.manager=org.apache.hadoop.hive.ql.security.HadoopDefaultMetastoreAuthenticator
  |hive.security.metastore.authorization.auth.reads=true
  |hive.security.metastore.authorization.manager=org.apache.hadoop.hive.ql.security.authorization.DefaultHiveMetastoreAuthorizationProvider
  |hive.serdes.using.metastore.for.schema=org.apache.hadoop.hive.ql.io.orc.OrcSerde,org.apache.hadoop.hive.serde2.lazy.LazySimpleSerDe,org.apache.hadoop.hive.serde2.columnar.ColumnarSerDe,org.apache.hadoop.hive.serde2.dynamic_type.DynamicSerDe,org.apache.hadoop.hive.serde2.MetadataTypedColumnsetSerDe,org.apache.hadoop.hive.serde2.columnar.LazyBinaryColumnarSerDe,org.apache.hadoop.hive.ql.io.parquet.serde.ParquetHiveSerDe,org.apache.hadoop.hive.serde2.lazybinary.LazyBinarySerDe
  |hive.server.read.socket.timeout=10s
  |hive.server.tcp.keepalive=true
  |hive.server2.allow.user.substitution=true
  |hive.server2.async.exec.async.compile=false
  |hive.server2.async.exec.keepalive.time=10s
  |hive.server2.async.exec.shutdown.timeout=10s
  |hive.server2.async.exec.threads=100
  |hive.server2.async.exec.wait.queue.size=100
  |hive.server2.authentication=NONE
  |hive.server2.authentication.ldap.groupClassKey=groupOfNames
  |hive.server2.authentication.ldap.groupMembershipKey=member
  |hive.server2.authentication.ldap.guidKey=uid
  |hive.server2.clear.dangling.scratchdir=false
  |hive.server2.clear.dangling.scratchdir.interval=1800s
  |hive.server2.compile.lock.timeout=0s
  |hive.server2.enable.doAs=true
  |hive.server2.global.init.file.location=/etc/hive/conf
  |hive.server2.idle.operation.timeout=0ms
  |hive.server2.idle.session.check.operation=false
  |hive.server2.idle.session.timeout=0ms
  |hive.server2.logging.operation.enabled=true
  |hive.server2.logging.operation.level=EXECUTION
  |hive.server2.logging.operation.log.location=/var/log/hive/operation_logs
  |hive.server2.long.polling.timeout=5000ms
  |hive.server2.map.fair.scheduler.queue=true
  |hive.server2.max.start.attempts=30
  |hive.server2.metrics.enabled=false
  |hive.server2.session.check.interval=0ms
  |hive.server2.sleep.interval.between.start.attempts=60s
  |hive.server2.support.dynamic.service.discovery=false
  |hive.server2.table.type.mapping=CLASSIC
  |hive.server2.tez.initialize.default.sessions=false
  |hive.server2.tez.sessions.per.default.queue=1
  |hive.server2.thrift.exponential.backoff.slot.length=100ms
  |hive.server2.thrift.http.max.idle.time=1800s
  |hive.server2.thrift.http.max.worker.threads=500
  |hive.server2.thrift.http.min.worker.threads=5
  |hive.server2.thrift.http.path=cliservice
  |hive.server2.thrift.http.port=10001
  |hive.server2.thrift.http.worker.keepalive.time=60s
  |hive.server2.thrift.login.timeout=20s
  |hive.server2.thrift.max.message.size=104857600
  |hive.server2.thrift.max.worker.threads=500
  |hive.server2.thrift.min.worker.threads=5
  |hive.server2.thrift.port=10000
  |hive.server2.thrift.sasl.qop=auth
  |hive.server2.thrift.worker.keepalive.time=60s
  |hive.server2.transport.mode=binary
  |hive.server2.use.SSL=false
  |hive.server2.webui.host=0.0.0.0
  |hive.server2.webui.max.historic.queries=25
  |hive.server2.webui.max.threads=50
  |hive.server2.webui.port=10002
  |hive.server2.webui.spnego.principal=HTTP/_HOST@EXAMPLE.COM
  |hive.server2.webui.use.spnego=false
  |hive.server2.webui.use.ssl=false
  |hive.server2.zookeeper.namespace=hiveserver2
  |hive.service.metrics.class=org.apache.hadoop.hive.common.metrics.metrics2.CodahaleMetrics
  |hive.service.metrics.file.frequency=5s
  |hive.service.metrics.file.location=/tmp/report.json
  |hive.service.metrics.reporter=JSON_FILE, JMX
  |hive.session.history.enabled=false
  |hive.session.id=9368ca67-5d25-4b95-ab3c-c89d8160f364
  |hive.session.silent=false
  |hive.skewjoin.key=100000
  |hive.skewjoin.mapjoin.map.tasks=10000
  |hive.skewjoin.mapjoin.min.split=33554432
  |hive.smbjoin.cache.rows=10000
  |hive.spark.client.connect.timeout=1000ms
  |hive.spark.client.future.timeout=60s
  |hive.spark.client.rpc.max.size=52428800
  |hive.spark.client.rpc.sasl.mechanisms=DIGEST-MD5
  |hive.spark.client.rpc.threads=8
  |hive.spark.client.secret.bits=256
  |hive.spark.client.server.connect.timeout=90000ms
  |hive.spark.dynamic.partition.pruning=false
  |hive.spark.dynamic.partition.pruning.map.join.only=false
  |hive.spark.dynamic.partition.pruning.max.data.size=104857600
  |hive.spark.job.monitor.timeout=60s
  |hive.ssl.protocol.blacklist=SSLv2,SSLv3
  |hive.stageid.rearrange=none
  |hive.start.cleanup.scratchdir=false
  |hive.stats.atomic=false
  |hive.stats.autogather=true
  |hive.stats.collect.rawdatasize=true
  |hive.stats.collect.scancols=true
  |hive.stats.collect.tablekeys=false
  |hive.stats.dbclass=fs
  |hive.stats.dbconnectionstring=jdbc:derby:;databaseName=TempStatsStore;create=true
  |hive.stats.deserialization.factor=1.0
  |hive.stats.fetch.column.stats=false
  |hive.stats.fetch.partition.stats=true
  |hive.stats.gather.num.threads=10
  |hive.stats.jdbc.timeout=30s
  |hive.stats.jdbcdriver=org.apache.derby.jdbc.EmbeddedDriver
  |hive.stats.join.factor=1.1
  |hive.stats.key.prefix.max.length=150
  |hive.stats.key.prefix.reserve.length=24
  |hive.stats.list.num.entries=10
  |hive.stats.map.num.entries=10
  |hive.stats.max.variable.length=100
  |hive.stats.ndv.error=20.0
  |hive.stats.reliable=false
  |hive.stats.retries.max=0
  |hive.stats.retries.wait=3000ms
  |hive.support.concurrency=true
  |hive.support.quoted.identifiers=column
  |hive.test.authz.sstd.hs2.mode=false
  |hive.test.mode=false
  |hive.test.mode.prefix=test_
  |hive.test.mode.samplefreq=32
  |hive.tez.auto.reducer.parallelism=false
  |hive.tez.container.size=-1
  |hive.tez.cpu.vcores=-1
  |hive.tez.dynamic.partition.pruning=true
  |hive.tez.dynamic.partition.pruning.max.data.size=104857600
  |hive.tez.dynamic.partition.pruning.max.event.size=1048576
  |hive.tez.exec.inplace.progress=true
  |hive.tez.exec.print.summary=false
  |hive.tez.input.format=org.apache.hadoop.hive.ql.io.HiveInputFormat
  |hive.tez.log.level=INFO
  |hive.tez.max.partition.factor=2.0
  |hive.tez.min.partition.factor=0.25
  |hive.tez.smb.number.waves=0.5
  |hive.transform.escape.input=false
  |hive.txn.manager=org.apache.hadoop.hive.ql.lockmgr.DummyTxnManager
  |hive.txn.max.open.batch=1000
  |hive.txn.timeout=300s
  |hive.typecheck.on.insert=true
  |hive.udtf.auto.progress=false
  |hive.unlock.numretries=10
  |hive.user.install.directory=hdfs:///user/
  |hive.variable.substitute=true
  |hive.variable.substitute.depth=40
  |hive.vectorized.execution.enabled=true
  |hive.vectorized.execution.reduce.enabled=false
  |hive.vectorized.execution.reduce.groupby.enabled=true
  |hive.vectorized.groupby.checkinterval=4096
  |hive.vectorized.groupby.flush.percent=0.1
  |hive.vectorized.groupby.maxentries=1000000
  |hive.warehouse.subdir.inherit.perms=true
  |hive.zookeeper.clean.extra.nodes=false
  |hive.zookeeper.client.port=2181
  |hive.zookeeper.connection.basesleeptime=1000ms
  |hive.zookeeper.connection.max.retries=3
  |hive.zookeeper.namespace=hive_zookeeper_namespace_hive
  |hive.zookeeper.quorum=quickstart.cloudera
  |hive.zookeeper.session.timeout=1200000ms
  |io.compression.codec.bzip2.library=system-native
  |io.compression.codecs=org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.BZip2Codec,org.apache.hadoop.io.compress.DeflateCodec,org.apache.hadoop.io.compress.SnappyCodec,org.apache.hadoop.io.compress.Lz4Codec
  |io.file.buffer.size=65536
  |io.map.index.interval=128
  |io.map.index.skip=0
  |io.mapfile.bloom.error.rate=0.005
  |io.mapfile.bloom.size=1048576
  |io.native.lib.available=true
  |io.seqfile.compress.blocksize=1000000
  |io.seqfile.lazydecompress=true
  |io.seqfile.local.dir=${hadoop.tmp.dir}/io/local
  |io.seqfile.sorter.recordlimit=1000000
  |io.serializations=org.apache.hadoop.io.serializer.WritableSerialization,org.apache.hadoop.io.serializer.avro.AvroSpecificSerialization,org.apache.hadoop.io.serializer.avro.AvroReflectSerialization
  |io.skip.checksum.errors=false
"""
"""
  |ipc.client.connect.max.retries=10
  |ipc.client.connect.max.retries.on.timeouts=45
  |ipc.client.connect.retry.interval=1000
  |ipc.client.connect.timeout=20000
  |ipc.client.connection.maxidletime=10000
  |ipc.client.fallback-to-simple-auth-allowed=false
  |ipc.client.idlethreshold=4000
  |ipc.client.kill.max=10
  |ipc.client.ping=true
  |ipc.client.rpc-timeout.ms=0
  |ipc.ping.interval=60000
  |ipc.server.listen.queue.size=128
  |ipc.server.log.slow.rpc=false
  |ipc.server.max.connections=0
  |javax.jdo.PersistenceManagerFactoryClass=org.datanucleus.api.jdo.JDOPersistenceManagerFactory
  |javax.jdo.option.ConnectionDriverName=org.apache.derby.jdbc.EmbeddedDriver
  |javax.jdo.option.ConnectionPassword=mine
  |javax.jdo.option.ConnectionURL=jdbc:derby:;databaseName=/tmp/spark-7a09d126-987b-45d1-b5a6-d2c3d5a8dca5/metastore;create=true
  |javax.jdo.option.ConnectionUserName=APP
  |javax.jdo.option.DetachAllOnCommit=true
  |javax.jdo.option.Multithreaded=true
  |javax.jdo.option.NonTransactionalRead=true
  |map.sort.class=org.apache.hadoop.util.QuickSort
  |mapreduce.admin.user.env=LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native:$JAVA_LIBRARY_PATH
  |mapreduce.am.max-attempts=2
  |mapreduce.app-submission.cross-platform=false
  |mapreduce.application.classpath=$HADOOP_MAPRED_HOME/*,$HADOOP_MAPRED_HOME/lib/*,$MR2_CLASSPATH
  |mapreduce.client.completion.pollinterval=5000
  |mapreduce.client.output.filter=FAILED
  |mapreduce.client.progressmonitor.pollinterval=1000
  |mapreduce.client.submit.file.replication=1
  |mapreduce.cluster.acls.enabled=false
  |mapreduce.cluster.local.dir=${hadoop.tmp.dir}/mapred/local
  |mapreduce.cluster.temp.dir=${hadoop.tmp.dir}/mapred/temp
  |mapreduce.fileoutputcommitter.algorithm.version=1
  |mapreduce.framework.name=yarn
  |mapreduce.ifile.readahead=true
  |mapreduce.ifile.readahead.bytes=4194304
  |mapreduce.input.fileinputformat.input.dir.recursive=false
  |mapreduce.input.fileinputformat.list-status.num-threads=1
  |mapreduce.input.fileinputformat.split.maxsize=256000000
  |mapreduce.input.fileinputformat.split.minsize=1
  |mapreduce.input.fileinputformat.split.minsize.per.node=1
  |mapreduce.input.fileinputformat.split.minsize.per.rack=1
  |mapreduce.input.lineinputformat.linespermap=1
  |mapreduce.job.acl-modify-job=
  |mapreduce.job.acl-view-job=
  |mapreduce.job.classloader=false
  |mapreduce.job.committer.setup.cleanup.needed=false
  |mapreduce.job.committer.task.cleanup.needed=false
  |mapreduce.job.complete.cancel.delegation.tokens=true
  |mapreduce.job.counters.groups.max=50
  |mapreduce.job.counters.max=120
  |mapreduce.job.emit-timeline-data=false
  |mapreduce.job.end-notification.max.attempts=5
  |mapreduce.job.end-notification.max.retry.interval=5000
  |mapreduce.job.end-notification.retry.attempts=0
  |mapreduce.job.end-notification.retry.interval=1000
  |mapreduce.job.hdfs-servers=${fs.defaultFS}
  |mapreduce.job.heap.memory-mb.ratio=0.8
  |mapreduce.job.jvm.numtasks=1
  |mapreduce.job.map.output.collector.class=org.apache.hadoop.mapred.MapTask$MapOutputBuffer
  |mapreduce.job.maps=2
  |mapreduce.job.max.split.locations=10
  |mapreduce.job.maxtaskfailures.per.tracker=3
  |mapreduce.job.queuename=default
  |mapreduce.job.redacted-properties=fs.s3a.access.key,fs.s3a.secret.key
  |mapreduce.job.reduce.shuffle.consumer.plugin.class=org.apache.hadoop.mapreduce.task.reduce.Shuffle
  |mapreduce.job.reduce.slowstart.completedmaps=0.8
  |mapreduce.job.reducer.preempt.delay.sec=0
  |mapreduce.job.reducer.unconditional-preempt.delay.sec=300
  |mapreduce.job.reduces=-1
  |mapreduce.job.running.map.limit=0
  |mapreduce.job.running.reduce.limit=0
  |mapreduce.job.speculative.minimum-allowed-tasks=10
  |mapreduce.job.speculative.retry-after-no-speculate=1000
  |mapreduce.job.speculative.retry-after-speculate=15000
  |mapreduce.job.speculative.slowtaskthreshold=1.0
  |mapreduce.job.speculative.speculative-cap-running-tasks=0.1
  |mapreduce.job.speculative.speculative-cap-total-tasks=0.01
  |mapreduce.job.split.metainfo.maxsize=10000000
  |mapreduce.job.token.tracking.ids.enabled=false
  |mapreduce.job.ubertask.enable=false
  |mapreduce.job.ubertask.maxmaps=9
  |mapreduce.job.ubertask.maxreduces=1
  |mapreduce.job.userlog.retain.hours=24
  |mapreduce.jobhistory.address=quickstart.cloudera:10020
  |mapreduce.jobhistory.admin.acl=*
  |mapreduce.jobhistory.admin.address=quickstart.cloudera:10033
  |mapreduce.jobhistory.cleaner.enable=true
  |mapreduce.jobhistory.cleaner.interval-ms=86400000
  |mapreduce.jobhistory.client.thread-count=10
  |mapreduce.jobhistory.datestring.cache.size=200000
  |mapreduce.jobhistory.done-dir=${yarn.app.mapreduce.am.staging-dir}/history/done
  |mapreduce.jobhistory.http.policy=HTTP_ONLY
  |mapreduce.jobhistory.intermediate-done-dir=${yarn.app.mapreduce.am.staging-dir}/history/done_intermediate
  |mapreduce.jobhistory.jhist.format=binary
  |mapreduce.jobhistory.joblist.cache.size=20000
  |mapreduce.jobhistory.keytab=/etc/security/keytab/jhs.service.keytab
  |mapreduce.jobhistory.loadedjob.tasks.max=-1
  |mapreduce.jobhistory.loadedjobs.cache.size=5
  |mapreduce.jobhistory.max-age-ms=604800000
  |mapreduce.jobhistory.minicluster.fixed.ports=false
  |mapreduce.jobhistory.move.interval-ms=180000
  |mapreduce.jobhistory.move.thread-count=3
  |mapreduce.jobhistory.principal=jhs/_HOST@REALM.TLD
  |mapreduce.jobhistory.recovery.enable=false
  |mapreduce.jobhistory.recovery.store.class=org.apache.hadoop.mapreduce.v2.hs.HistoryServerFileSystemStateStoreService
  |mapreduce.jobhistory.recovery.store.fs.uri=${hadoop.tmp.dir}/mapred/history/recoverystore
  |mapreduce.jobhistory.webapp.address=quickstart.cloudera:19888
  |mapreduce.jobhistory.webapp.https.address=quickstart.cloudera:19890
  |mapreduce.jobtracker.address=local
  |mapreduce.jobtracker.expire.trackers.interval=600000
  |mapreduce.jobtracker.handler.count=10
  |mapreduce.jobtracker.heartbeats.in.second=100
  |mapreduce.jobtracker.http.address=0.0.0.0:50030
  |mapreduce.jobtracker.instrumentation=org.apache.hadoop.mapred.JobTrackerMetricsInst
  |mapreduce.jobtracker.jobhistory.block.size=3145728
  |mapreduce.jobtracker.jobhistory.lru.cache.size=5
  |mapreduce.jobtracker.jobhistory.task.numberprogresssplits=12
  |mapreduce.jobtracker.maxtasks.perjob=-1
  |mapreduce.jobtracker.persist.jobstatus.active=true
  |mapreduce.jobtracker.persist.jobstatus.dir=/jobtracker/jobsInfo
  |mapreduce.jobtracker.persist.jobstatus.hours=1
  |mapreduce.jobtracker.restart.recover=false
  |mapreduce.jobtracker.retiredjobs.cache.size=1000
  |mapreduce.jobtracker.staging.root.dir=${hadoop.tmp.dir}/mapred/staging
  |mapreduce.jobtracker.system.dir=${hadoop.tmp.dir}/mapred/system
  |mapreduce.jobtracker.taskcache.levels=2
  |mapreduce.jobtracker.tasktracker.maxblacklists=4
  |mapreduce.local.clientfactory.class.name=org.apache.hadoop.mapred.LocalClientFactory
  |mapreduce.map.cpu.vcores=1
  |mapreduce.map.java.opts=-Djava.net.preferIPv4Stack=true -Xmx52428800
  |mapreduce.map.log.level=INFO
  |mapreduce.map.maxattempts=4
  |mapreduce.map.memory.mb=128
  |mapreduce.map.output.compress=true
  |mapreduce.map.output.compress.codec=org.apache.hadoop.io.compress.SnappyCodec
  |mapreduce.map.skip.maxrecords=0
  |mapreduce.map.sort.spill.percent=0.8
  |mapreduce.map.speculative=false
  |mapreduce.output.fileoutputformat.compress=false
  |mapreduce.output.fileoutputformat.compress.codec=org.apache.hadoop.io.compress.DefaultCodec
  |mapreduce.output.fileoutputformat.compress.type=BLOCK
  |mapreduce.reduce.cpu.vcores=1
  |mapreduce.reduce.input.buffer.percent=0.0
  |mapreduce.reduce.java.opts=-Djava.net.preferIPv4Stack=true -Xmx52428800
  |mapreduce.reduce.log.level=INFO
  |mapreduce.reduce.markreset.buffer.percent=0.0
  |mapreduce.reduce.maxattempts=4
  |mapreduce.reduce.memory.mb=128
  |mapreduce.reduce.merge.inmem.threshold=1000
  |mapreduce.reduce.shuffle.connect.timeout=180000
  |mapreduce.reduce.shuffle.fetch.retry.enabled=${yarn.nodemanager.recovery.enabled}
  |mapreduce.reduce.shuffle.fetch.retry.interval-ms=1000
  |mapreduce.reduce.shuffle.fetch.retry.timeout-ms=30000
  |mapreduce.reduce.shuffle.input.buffer.percent=0.70
  |mapreduce.reduce.shuffle.memory.limit.percent=0.25
  |mapreduce.reduce.shuffle.merge.percent=0.66
  |mapreduce.reduce.shuffle.parallelcopies=10
  |mapreduce.reduce.shuffle.read.timeout=180000
  |mapreduce.reduce.shuffle.retry-delay.max.ms=60000
  |mapreduce.reduce.skip.maxgroups=0
  |mapreduce.reduce.speculative=true
  |mapreduce.shuffle.connection-keep-alive.enable=false
  |mapreduce.shuffle.connection-keep-alive.timeout=5
  |mapreduce.shuffle.listen.queue.size=128
  |mapreduce.shuffle.max.connections=0
  |mapreduce.shuffle.max.threads=0
  |mapreduce.shuffle.port=13562
  |mapreduce.shuffle.ssl.enabled=false
  |mapreduce.shuffle.ssl.file.buffer.size=65536
  |mapreduce.shuffle.transfer.buffer.size=131072
  |mapreduce.task.combine.progress.records=10000
  |mapreduce.task.exit.timeout=60000
  |mapreduce.task.exit.timeout.check-interval-ms=20000
  |mapreduce.task.files.preserve.failedtasks=false
  |mapreduce.task.io.sort.factor=64
  |mapreduce.task.io.sort.mb=16
  |mapreduce.task.merge.progress.records=10000
  |mapreduce.task.profile=false
  |mapreduce.task.profile.map.params=${mapreduce.task.profile.params}
  |mapreduce.task.profile.maps=0-2
  |mapreduce.task.profile.params=-agentlib:hprof=cpu=samples,heap=sites,force=n,thread=y,verbose=n,file=%s
  |mapreduce.task.profile.reduce.params=${mapreduce.task.profile.params}
  |mapreduce.task.profile.reduces=0-2
  |mapreduce.task.skip.start.attempts=2
  |mapreduce.task.timeout=600000
  |mapreduce.task.tmp.dir=./tmp
  |mapreduce.task.userlog.limit.kb=0
  |mapreduce.tasktracker.dns.interface=default
  |mapreduce.tasktracker.dns.nameserver=default
  |mapreduce.tasktracker.healthchecker.interval=60000
  |mapreduce.tasktracker.healthchecker.script.timeout=600000
  |mapreduce.tasktracker.http.address=0.0.0.0:50060
  |mapreduce.tasktracker.http.threads=40
  |mapreduce.tasktracker.indexcache.mb=10
  |mapreduce.tasktracker.instrumentation=org.apache.hadoop.mapred.TaskTrackerMetricsInst
  |mapreduce.tasktracker.local.dir.minspacekill=0
  |mapreduce.tasktracker.local.dir.minspacestart=0
  |mapreduce.tasktracker.map.tasks.maximum=2
  |mapreduce.tasktracker.outofband.heartbeat=false
  |mapreduce.tasktracker.reduce.tasks.maximum=2
  |mapreduce.tasktracker.report.address=127.0.0.1:0
  |mapreduce.tasktracker.taskcontroller=org.apache.hadoop.mapred.DefaultTaskController
  |mapreduce.tasktracker.taskmemorymanager.monitoringinterval=5000
  |mapreduce.tasktracker.tasks.sleeptimebeforesigkill=5000
  |net.topology.impl=org.apache.hadoop.net.NetworkTopology
  |net.topology.node.switch.mapping.impl=org.apache.hadoop.net.ScriptBasedMapping
  |net.topology.script.file.name=/etc/hadoop/conf.cloudera.yarn/topology.py
  |net.topology.script.number.args=100
  |nfs.allow.insecure.ports=true
  |nfs.dump.dir=/tmp/.hdfs-nfs
  |nfs.exports.allowed.hosts=* rw
  |nfs.mountd.port=4242
  |nfs.rtmax=1048576
  |nfs.server.port=2049
  |nfs.wtmax=1048576
  |parquet.memory.pool.ratio=0.5
  |rpc.metrics.quantile.enable=false
  |s3.blocksize=67108864
  |s3.bytes-per-checksum=512
  |s3.client-write-packet-size=65536
  |s3.replication=3
  |s3.stream-buffer-size=4096
  |s3native.blocksize=67108864
  |s3native.bytes-per-checksum=512
  |s3native.client-write-packet-size=65536
  |s3native.replication=3
  |s3native.stream-buffer-size=4096
  |spark.driver.memory=52428800
  |spark.dynamicAllocation.enabled=true
  |spark.dynamicAllocation.initialExecutors=1
  |spark.dynamicAllocation.maxExecutors=2147483647
  |spark.dynamicAllocation.minExecutors=1
  |spark.executor.cores=1
  |spark.executor.memory=52428800
  |spark.shuffle.service.enabled=true
  |spark.sql.queryExecutionListeners=com.cloudera.spark.lineage.ClouderaNavigatorListener
  |spark.yarn.driver.memoryOverhead=64
  |spark.yarn.executor.memoryOverhead=64
  |stream.stderr.reporter.enabled=true
  |stream.stderr.reporter.prefix=reporter:
  |tfile.fs.input.buffer.size=262144
  |tfile.fs.output.buffer.size=262144
  |tfile.io.chunk.size=1048576
  |yarn.acl.enable=true
  |yarn.admin.acl=*
  |yarn.am.blacklisting.disable-failure-threshold=0.8f
  |yarn.am.blacklisting.enabled=true
  |yarn.am.liveness-monitor.expiry-interval-ms=600000
  |yarn.app.attempt.diagnostics.limit.kc=64
  |yarn.app.mapreduce.am.admin.user.env=LD_LIBRARY_PATH=$HADOOP_COMMON_HOME/lib/native:$JAVA_LIBRARY_PATH
  |yarn.app.mapreduce.am.command-opts=-Djava.net.preferIPv4Stack=true -Xmx52428800
  |yarn.app.mapreduce.am.container.log.backups=0
  |yarn.app.mapreduce.am.container.log.limit.kb=0
  |yarn.app.mapreduce.am.containerlauncher.threadpool-initial-size=10
  |yarn.app.mapreduce.am.job.committer.cancel-timeout=60000
  |yarn.app.mapreduce.am.job.committer.commit-window=10000
  |yarn.app.mapreduce.am.job.task.listener.thread-count=30
  |yarn.app.mapreduce.am.resource.cpu-vcores=1
  |yarn.app.mapreduce.am.resource.mb=128
  |yarn.app.mapreduce.am.scheduler.heartbeat.interval-ms=1000
  |yarn.app.mapreduce.am.staging-dir=/user
  |yarn.app.mapreduce.client-am.ipc.max-retries=3
  |yarn.app.mapreduce.client-am.ipc.max-retries-on-timeouts=3
  |yarn.app.mapreduce.client.job.max-retries=3
  |yarn.app.mapreduce.client.job.retry-interval=2000
  |yarn.app.mapreduce.client.max-retries=3
  |yarn.app.mapreduce.shuffle.log.backups=0
  |yarn.app.mapreduce.shuffle.log.limit.kb=0
  |yarn.app.mapreduce.shuffle.log.separate=true
  |yarn.app.mapreduce.task.container.log.backups=0
  |yarn.application.classpath=$HADOOP_CLIENT_CONF_DIR,$HADOOP_CONF_DIR,$HADOOP_COMMON_HOME/*,$HADOOP_COMMON_HOME/lib/*,$HADOOP_HDFS_HOME/*,$HADOOP_HDFS_HOME/lib/*,$HADOOP_YARN_HOME/*,$HADOOP_YARN_HOME/lib/*
  |yarn.bin.path=/usr/lib/hadoop/bin/yarn
  |yarn.client.application-client-protocol.poll-interval-ms=200
  |yarn.client.failover-proxy-provider=org.apache.hadoop.yarn.client.ConfiguredRMFailoverProxyProvider
  |yarn.client.failover-retries=0
  |yarn.client.failover-retries-on-socket-timeouts=0
  |yarn.client.max-cached-nodemanagers-proxies=0
  |yarn.client.nodemanager-client-async.thread-pool-max-size=500
  |yarn.client.nodemanager-connect.max-wait-ms=180000
  |yarn.client.nodemanager-connect.retry-interval-ms=10000
  |yarn.fail-fast=false
  |yarn.http.policy=HTTP_ONLY
  |yarn.ipc.rpc.class=org.apache.hadoop.yarn.ipc.HadoopYarnProtoRPC
  |yarn.log-aggregation-enable=false
  |yarn.log-aggregation.retain-check-interval-seconds=-1
  |yarn.log-aggregation.retain-seconds=-1
  |yarn.nm.liveness-monitor.expiry-interval-ms=600000
  |yarn.nodemanager.address=${yarn.nodemanager.hostname}:0
  |yarn.nodemanager.admin-env=MALLOC_ARENA_MAX=$MALLOC_ARENA_MAX
  |yarn.nodemanager.aux-services.mapreduce_shuffle.class=org.apache.hadoop.mapred.ShuffleHandler
  |yarn.nodemanager.container-executor.class=org.apache.hadoop.yarn.server.nodemanager.DefaultContainerExecutor
  |yarn.nodemanager.container-manager.thread-count=20
  |yarn.nodemanager.container-metrics.unregister-delay-ms=10000
  |yarn.nodemanager.container-monitor.interval-ms=3000
  |yarn.nodemanager.container-monitor.procfs-tree.smaps-based-rss.enabled=false
  |yarn.nodemanager.default-container-executor.log-dirs.permissions=710
  |yarn.nodemanager.delete.debug-delay-sec=0
  |yarn.nodemanager.delete.thread-count=4
  |yarn.nodemanager.disk-health-checker.interval-ms=120000
  |yarn.nodemanager.disk-health-checker.max-disk-utilization-per-disk-percentage=90.0
  |yarn.nodemanager.disk-health-checker.min-free-space-per-disk-mb=0
  |yarn.nodemanager.disk-health-checker.min-healthy-disks=0.25
  |yarn.nodemanager.docker-container-executor.exec-name=/usr/bin/docker
  |yarn.nodemanager.env-whitelist=JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,HADOOP_CONF_DIR,HADOOP_YARN_HOME
  |yarn.nodemanager.health-checker.interval-ms=600000
  |yarn.nodemanager.health-checker.script.timeout-ms=1200000
  |yarn.nodemanager.hostname=0.0.0.0
  |yarn.nodemanager.keytab=/etc/krb5.keytab
  |yarn.nodemanager.003-Linux-container-executor.cgroups.hierarchy=/hadoop-yarn
  |yarn.nodemanager.003-Linux-container-executor.cgroups.mount=false
  |yarn.nodemanager.003-Linux-container-executor.cgroups.strict-resource-usage=false
  |yarn.nodemanager.003-Linux-container-executor.nonsecure-mode.limit-users=true
  |yarn.nodemanager.003-Linux-container-executor.nonsecure-mode.local-user=nobody
  |yarn.nodemanager.003-Linux-container-executor.nonsecure-mode.user-pattern=^[_.A-Za-z0-9][-@_.A-Za-z0-9]{0,255}?[$]?$
  |yarn.nodemanager.003-Linux-container-executor.resources-handler.class=org.apache.hadoop.yarn.server.nodemanager.util.DefaultLCEResourcesHandler
  |yarn.nodemanager.local-cache.max-files-per-directory=8192
  |yarn.nodemanager.local-dirs=${hadoop.tmp.dir}/nm-local-dir
  |yarn.nodemanager.localizer.address=${yarn.nodemanager.hostname}:8040
  |yarn.nodemanager.localizer.cache.cleanup.interval-ms=600000
  |yarn.nodemanager.localizer.cache.target-size-mb=10240
  |yarn.nodemanager.localizer.client.thread-count=5
  |yarn.nodemanager.localizer.fetch.thread-count=4
  |yarn.nodemanager.log-aggregation.compression-type=none
  |yarn.nodemanager.log-aggregation.roll-monitoring-interval-seconds=-1
  |yarn.nodemanager.log-dirs=${yarn.log.dir}/userlogs
  |yarn.nodemanager.log.retain-seconds=10800
  |yarn.nodemanager.logaggregation.threadpool-size-max=100
  |yarn.nodemanager.pmem-check-enabled=true
  |yarn.nodemanager.process-kill-wait.ms=2000
  |yarn.nodemanager.recovery.compaction-interval-secs=3600
  |yarn.nodemanager.recovery.dir=${hadoop.tmp.dir}/yarn-nm-recovery
  |yarn.nodemanager.recovery.enabled=false
  |yarn.nodemanager.remote-app-log-dir=/tmp/logs
  |yarn.nodemanager.remote-app-log-dir-suffix=logs
  |yarn.nodemanager.resource.cpu-vcores=8
  |yarn.nodemanager.resource.memory-mb=8192
  |yarn.nodemanager.resource.percentage-physical-cpu-limit=100
  |yarn.nodemanager.resourcemanager.minimum.version=NONE
  |yarn.nodemanager.sleep-delay-before-sigkill.ms=250
  |yarn.nodemanager.vmem-check-enabled=false
  |yarn.nodemanager.vmem-pmem-ratio=2.1
  |yarn.nodemanager.webapp.address=${yarn.nodemanager.hostname}:8042
  |yarn.resourcemanager.address=quickstart.cloudera:8032
  |yarn.resourcemanager.admin.address=quickstart.cloudera:8033
  |yarn.resourcemanager.admin.client.thread-count=1
  |yarn.resourcemanager.am-rm-tokens.master-key-rolling-interval-secs=86400
  |yarn.resourcemanager.am.max-attempts=2
  |yarn.resourcemanager.amlauncher.log.command=false
  |yarn.resourcemanager.amlauncher.thread-count=50
  |yarn.resourcemanager.amliveliness-monitor.interval-ms=1000
  |yarn.resourcemanager.client.thread-count=50
  |yarn.resourcemanager.configuration.provider-class=org.apache.hadoop.yarn.LocalConfigurationProvider
  |yarn.resourcemanager.connect.max-wait.ms=900000
  |yarn.resourcemanager.connect.retry-interval.ms=30000
  |yarn.resourcemanager.container-tokens.master-key-rolling-interval-secs=86400
  |yarn.resourcemanager.container.liveness-monitor.interval-ms=600000
  |yarn.resourcemanager.delayed.delegation-token.removal-interval-ms=30000
  |yarn.resourcemanager.fail-fast=${yarn.fail-fast}
  |yarn.resourcemanager.fs.state-store.retry-policy-spec=2000, 500
  |yarn.resourcemanager.fs.state-store.uri=${hadoop.tmp.dir}/yarn/system/rmstore
  |yarn.resourcemanager.ha.automatic-failover.embedded=true
  |yarn.resourcemanager.ha.automatic-failover.enabled=true
  |yarn.resourcemanager.ha.automatic-failover.zk-base-path=/yarn-leader-election
  |yarn.resourcemanager.ha.enabled=false
  |yarn.resourcemanager.hostname=0.0.0.0
  |yarn.resourcemanager.keytab=/etc/krb5.keytab
  |yarn.resourcemanager.max-completed-applications=10000
  |yarn.resourcemanager.max-log-aggregation-diagnostics-in-memory=10
  |yarn.resourcemanager.nm.liveness-monitor.interval-ms=1000
  |yarn.resourcemanager.nodemanager-connect-retries=10
  |yarn.resourcemanager.nodemanager.minimum.version=NONE
  |yarn.resourcemanager.nodemanagers.heartbeat-interval-ms=1000
  |yarn.resourcemanager.proxy-user-privileges.enabled=false
  |yarn.resourcemanager.recovery.enabled=false
  |yarn.resourcemanager.resource-tracker.address=quickstart.cloudera:8031
  |yarn.resourcemanager.resource-tracker.client.thread-count=50
  |yarn.resourcemanager.scheduler.address=quickstart.cloudera:8030
  |yarn.resourcemanager.scheduler.class=org.apache.hadoop.yarn.server.resourcemanager.scheduler.fair.FairScheduler
  |yarn.resourcemanager.scheduler.client.thread-count=50
  |yarn.resourcemanager.scheduler.monitor.enable=false
  |yarn.resourcemanager.scheduler.monitor.policies=org.apache.hadoop.yarn.server.resourcemanager.monitor.capacity.ProportionalCapacityPreemptionPolicy
  |yarn.resourcemanager.state-store.max-completed-applications=${yarn.resourcemanager.max-completed-applications}
  |yarn.resourcemanager.store.class=org.apache.hadoop.yarn.server.resourcemanager.recovery.FileSystemRMStateStore
  |yarn.resourcemanager.system-metrics-publisher.dispatcher.pool-size=10
  |yarn.resourcemanager.system-metrics-publisher.enabled=false
  |yarn.resourcemanager.webapp.address=quickstart.cloudera:8088
  |yarn.resourcemanager.webapp.delegation-token-auth-filter.enabled=true
  |yarn.resourcemanager.webapp.https.address=quickstart.cloudera:8090
  |yarn.resourcemanager.work-preserving-recovery.enabled=false
  |yarn.resourcemanager.work-preserving-recovery.scheduling-wait-ms=10000
  |yarn.resourcemanager.zk-acl=world:anyone:rwcda
  |yarn.resourcemanager.zk-num-retries=1000
  |yarn.resourcemanager.zk-retry-interval-ms=1000
  |yarn.resourcemanager.zk-state-store.parent-path=/rmstore
  |yarn.resourcemanager.zk-timeout-ms=10000
  |yarn.scheduler.increment-allocation-mb=512
  |yarn.scheduler.increment-allocation-vcores=1
  |yarn.scheduler.maximum-allocation-mb=2816
  |yarn.scheduler.maximum-allocation-vcores=2
  |yarn.scheduler.minimum-allocation-mb=1
  |yarn.scheduler.minimum-allocation-vcores=1
  |yarn.timeline-service.address=${yarn.timeline-service.hostname}:10200
  |yarn.timeline-service.client.max-retries=30
  |yarn.timeline-service.client.retry-interval-ms=1000
  |yarn.timeline-service.enabled=false
  |yarn.timeline-service.handler-thread-count=10
  |yarn.timeline-service.hostname=0.0.0.0
  |yarn.timeline-service.http-authentication.simple.anonymous.allowed=true
  |yarn.timeline-service.http-authentication.type=simple
  |yarn.timeline-service.keytab=/etc/krb5.keytab
  |yarn.timeline-service.leveldb-timeline-store.path=${hadoop.tmp.dir}/yarn/timeline
  |yarn.timeline-service.leveldb-timeline-store.read-cache-size=104857600
  |yarn.timeline-service.leveldb-timeline-store.start-time-read-cache-size=10000
  |yarn.timeline-service.leveldb-timeline-store.start-time-write-cache-size=10000
  |yarn.timeline-service.leveldb-timeline-store.ttl-interval-ms=300000
  |yarn.timeline-service.store-class=org.apache.hadoop.yarn.server.timeline.LeveldbTimelineStore
  |yarn.timeline-service.ttl-enable=true
  |yarn.timeline-service.ttl-ms=604800000
  |yarn.timeline-service.webapp.address=${yarn.timeline-service.hostname}:8188
  |yarn.timeline-service.webapp.https.address=${yarn.timeline-service.hostname}:8190
  |zlib.compress.level=DEFAULT_COMPRESSION
  |
"""